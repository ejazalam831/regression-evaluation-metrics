{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Functions in Linear Regression: A Complete Guide to Model Evaluation"
      ],
      "metadata": {
        "id": "Y37M4B39sqeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with linear regression models, one of the most important question we face is: *\"How do we know if our model's predictions are any good?\"* This is where loss functions come in, where they tell us exactly how well (or poorly) our model's predictions match reality.\n",
        "\n",
        "In this comprehensive guide, we'll explore the five most important loss functions we need to know: **MAE, MSE, RMSE, R-squared, and MAPE**.\n",
        "\n",
        "**Note:** These loss functions are specifically for **regression models** which predict continuous numerical values like prices, or temperatures.\n"
      ],
      "metadata": {
        "id": "Muqfro7DtCpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outline:\n",
        "1. What Are Loss Functions?\n",
        "2. Mean Absolute Error (MAE)\n",
        "3. Mean Squared Error (MSE)\n",
        "4. Root Mean Squared Error (RMSE)\n",
        "5. R-squared (Coefficient of Determination)\n",
        "6. Mean Absolute Percentage Error (MAPE)\n",
        "7. Choosing the Right Loss Function"
      ],
      "metadata": {
        "id": "piwxR3natVIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What Are Loss Functions?\n",
        "\n",
        "Loss functions let us *numerically know how far off the modelâ€™s predictions are from the actual values*. They measure the difference between what the model predicts and what actually happened, but they do it in different ways that emphasize different aspects of accuracy.\n"
      ],
      "metadata": {
        "id": "iVnnJ_48teJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample Data Setup\n",
        "\n",
        "First, let's set up our sample data that we'll use throughout all examples.\n",
        "\n",
        "This will be a small dataset representing 5 tables at a restaurant with their actual tips and we'll assume our model's predicted tips based on the total bill. The goal is to evaluate how well those predictions are.\n"
      ],
      "metadata": {
        "id": "vxrVuV0vFcMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhYVSKRTsnAA",
        "outputId": "89a3fb76-d1ff-4a43-f2bd-5db0136a665b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Table  Actual_Tip  Predicted_Tip\n",
            "0      1         4.0            3.5\n",
            "1      2         6.0            5.8\n",
            "2      3         2.0            2.9\n",
            "3      4         8.0            7.2\n",
            "4      5         3.5            3.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Our sample data - 5 restaurant tables\n",
        "actual_tips = np.array([4.00, 6.00, 2.00, 8.00, 3.50])\n",
        "predicted_tips = np.array([3.50, 5.80, 2.90, 7.20, 3.10])\n",
        "\n",
        "# Create a DataFrame for easy viewing\n",
        "data = pd.DataFrame({\n",
        "    'Table': [1, 2, 3, 4, 5],\n",
        "    'Actual_Tip': actual_tips,\n",
        "    'Predicted_Tip': predicted_tips\n",
        "})\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's explore how each loss function evaluates these predictions!"
      ],
      "metadata": {
        "id": "UL2KiBRxJecF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mean Absolute Error (MAE)\n",
        "\n",
        "MAE calculates the average of the absolute differences between predicted and actual values across the entire dataset. The other way to think about it is as: *\"On average, how far off are my predictions?\"*\n",
        "\n",
        "It is the simplest, computationally inexpensive and most intuitive loss function.\n",
        "\n",
        "**Formula:** MAE = (1/n) Ã— Î£|actual - predicted|"
      ],
      "metadata": {
        "id": "5KBUbW2PuuhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Calculation"
      ],
      "metadata": {
        "id": "zvFbshLJSruI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Manual Calculation:**\n",
        "\n",
        "Let's calculate the absolute error for each prediction:\n",
        "\n",
        "| Table | Actual Tip | Predicted Tip | Absolute Error |\n",
        "| ----- | ---------- | ------------- | -------------- |\n",
        "| 1     | \\$4.00     | \\$3.50        | \\$0.50         |\n",
        "| 2     | \\$6.00     | \\$5.80        | \\$0.20         |\n",
        "| 3     | \\$2.00     | \\$2.90        | \\$0.90         |\n",
        "| 4     | \\$8.00     | \\$7.20        | \\$0.80         |\n",
        "| 5     | \\$3.50     | \\$3.10        | \\$0.40         |\n",
        "\n",
        "\n",
        "**MAE = (0.50 + 0.20 + 0.90 + 0.80 + 0.40) Ã· 5 = $0.56**\n"
      ],
      "metadata": {
        "id": "mijBTEorS5Gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using sklearn:**"
      ],
      "metadata": {
        "id": "jaPK4z4MTaTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mae = mean_absolute_error(actual_tips, predicted_tips)\n",
        "print(f\"MAE: ${mae:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qGe7ldCVrPK",
        "outputId": "0fda0cbc-9735-49b5-bd94-9ead1de35e26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: $0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This basically means our model is off by an average of 56 cents per prediction."
      ],
      "metadata": {
        "id": "G6GoGcsoV1Qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to Use MAE\n",
        "\n",
        "**Metric Type:** ðŸ”´ **Negative Metric** (Lower is Better)\n",
        "- We want MAE to be as close to 0 as possible\n",
        "- A perfect model would have MAE = 0\n",
        "\n",
        "**Key Properties:**\n",
        "- **Easy to interpret:** The result is in the same units as the target variable\n",
        "- **Robust to outliers:** One really bad prediction won't skew the entire score\n",
        "- **Equal treatment:** All errors are weighted the same, regardless of size\n",
        "\n",
        "\n",
        "**Best for:**\n",
        "\n",
        "When we want a straightforward measure that's easy to explain to stakeholders, and when outliers shouldn't dominate our evaluation. Some examples include:\n",
        "\n",
        "- **Delivery time estimation:** For food delivery apps, MAE of 8 minutes means customers can expect delivery estimates to be off by about 8 minutes on average.\n",
        "- **Budget forecasting:** When predicting project costs, MAE gives us the average dollar amount our estimates are typically off by."
      ],
      "metadata": {
        "id": "WVxUbcBPZX-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Mean Squared Error (MSE)\n",
        "\n",
        "MSE calculates the average of the squared differences between predicted and actual values across the entire dataset. Another way to think about it is as: *\"How much do I penalize bigger mistakes?\"*\n",
        "\n",
        "\n",
        "**Formula:** MSE = (1/n) Ã— Î£(actual - predicted)Â²"
      ],
      "metadata": {
        "id": "IQvkAPMHvEpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Calculation"
      ],
      "metadata": {
        "id": "QtkuTCJ2htor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Manual Calculation:**\n",
        "\n",
        "Let's calculate the squared error for each prediction:\n",
        "\n",
        "| Table | Actual Tip | Predicted Tip | Error | Squared Error |\n",
        "|-------|------------|---------------|-------|---------------|\n",
        "| 1     | \\$4.00      | \\$3.50         | \\$0.50 | \\$0.25        |\n",
        "| 2     | \\$6.00      | \\$5.80         | \\$0.20 | \\$0.04        |\n",
        "| 3     | \\$2.00      | \\$2.90         | \\-$0.90| \\$0.81        |\n",
        "| 4     | \\$8.00      | \\$7.20         | \\$0.80 | \\$0.64        |\n",
        "| 5     | \\$3.50      | \\$3.10         | \\$0.40 | \\$0.16        |\n",
        "\n",
        "**MSE = (0.25 + 0.04 + 0.81 + 0.64 + 0.16) Ã· 5 = $0.38**\n"
      ],
      "metadata": {
        "id": "zpH_7koFh1a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using sklearn:**"
      ],
      "metadata": {
        "id": "UwJrkkTPibwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(actual_tips, predicted_tips)\n",
        "print(f\"MSE: ${mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e_JHuq8xHD_",
        "outputId": "6630318a-b664-4708-9809-96f9333f00d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: $0.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see how the \\$0.90 error from Table 3 contributes much more to the final score (\\$0.81 out of \\$1.90 total) than the \\$0.20 error from Table 2 ($0.04)."
      ],
      "metadata": {
        "id": "uOAnTyR7i7j9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to Use MSE\n",
        "\n",
        "**Metric Type:** ðŸ”´ **Negative Metric** (Lower is Better)\n",
        "- We want MSE to be as close to 0 as possible\n",
        "- MSE = 0 means perfect predictions\n",
        "\n",
        "**Key Properties:**\n",
        "- **Penalizes large errors:** If being very wrong is much worse than being slightly wrong\n",
        "- **Sensitive to outliers:** One bad prediction can significantly impact the score\n",
        "\n",
        "**Best for:**\n",
        "\n",
        "When large errors are costly, and we want our model to avoid them at all costs. Some examples include:\n",
        "\n",
        "- **House price prediction:** When predicting home values, being off by \\$100,000 is much worse than being off by \\$10,000. MSE heavily penalizes those large errors, which aligns with the real-world impact.\n",
        "- **Financial modeling:** In stock price or portfolio value prediction, large errors can lead to significant financial losses, so heavily penalizing them would makes sense.\n"
      ],
      "metadata": {
        "id": "4kMC4qM5xBS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Root Mean Squared Error (RMSE)\n",
        "\n",
        "RMSE is simply the square root of MSE. It brings the error metric back to the same units as the original data while maintaining MSE's sensitivity to large errors.\n",
        "\n",
        "\n",
        "**Formula:** RMSE = âˆšMSE = âˆš[(1/n) Ã— Î£(actual - predicted)Â²]\n"
      ],
      "metadata": {
        "id": "sFYd5C17xuQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Calculation"
      ],
      "metadata": {
        "id": "4AKbNbXFWUX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Manual Calculation:**\n",
        "\n",
        "Using our MSE result from above:\n",
        "\n",
        "**RMSE = âˆš$0.38 = \\$0.62**\n"
      ],
      "metadata": {
        "id": "T4p0yTTqWVXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using sklearn:**"
      ],
      "metadata": {
        "id": "F78LpWlMWjm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
        "\n",
        "# Method 1: Square root of MSE\n",
        "mse = mean_squared_error(actual_tips, predicted_tips)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"RMSE: ${rmse:.2f}\")\n",
        "\n",
        "# Method 2: Use the dedicated RMSE function\n",
        "rmse = root_mean_squared_error(actual_tips, predicted_tips)\n",
        "print(f\"RMSE: ${rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJDOCcetyrQG",
        "outputId": "c37ec75d-a94e-472f-8e63-7d767ec8aaf9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: $0.62\n",
            "RMSE: $0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to Use RMSE\n",
        "\n",
        "**Metric Type:** ðŸ”´ **Negative Metric** (Lower is Better)\n",
        "- We want RMSE to be as close to 0 as possible\n",
        "- RMSE is always â‰¥ MAE, with equality only when all errors are identical\n",
        "\n",
        "**Key Properties:**\n",
        "- **Interpretable scale:** Results are in the same units as the target variable\n",
        "- **Penalizes large errors:** Like MSE, but easier to understand\n",
        "\n",
        "**Best for:**\n",
        "\n",
        "When we want the mathematical properties of MSE but need results that are easy to interpret and communicate. Some examples include:\n",
        "- **Energy consumption forecasting:** When predicting building energy usage in kWh, RMSE gives us an interpretable error metric while still penalizing large prediction errors that could lead to power grid issues.\n",
        "- **Weather forecasting:** Temperature predictions where RMSE in degrees tells us typical forecast accuracy while emphasizing the importance of avoiding extreme errors.\n",
        "\n"
      ],
      "metadata": {
        "id": "3oXdBoFsyd_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. R-squared (Coefficient of Determination)\n",
        "\n",
        "R-squared is quite different from the previous metrics we discussed above. Instead of measuring error, it measures how much of the variance in our target variable our model can explain. We can also think of it as: *\"What percentage of the story does my model capture?\"*\n",
        "\n",
        "\n",
        "**Formula:** RÂ² = 1 - (SS_res / SS_tot)\n",
        "- SS_res = Sum of squares of residuals = Î£(actual - predicted)Â²  \n",
        "- SS_tot = Total sum of squares = Î£(actual - mean_of_actual)Â²\n"
      ],
      "metadata": {
        "id": "STsaPr_EzZKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Calculation"
      ],
      "metadata": {
        "id": "R4OkrbaJMaf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Manual Calculation:**\n",
        "\n",
        "Let's expand our example with the mean of actual tips:\n",
        "\n",
        "| Table | Actual Tip | Predicted Tip | Mean Tip | (Actual-Predicted)Â² | (Actual-Mean)Â² |\n",
        "|-------|------------|---------------|----------|---------------------|----------------|\n",
        "| 1     | \\$4.00      | \\$3.50         | \\$4.70    | \\$0.25              | \\$0.49         |\n",
        "| 2     | \\$6.00      | \\$5.80         | \\$4.70    | \\$0.04              | \\$1.69         |\n",
        "| 3     | \\$2.00      | \\$2.90         | \\$4.70    | \\$0.81              | \\$7.29         |\n",
        "| 4     | \\$8.00      | \\$7.20         | \\$4.70    | \\$0.64              | \\$10.89        |\n",
        "| 5     | \\$3.50      | \\$3.10         | \\$4.70    | \\$0.16              | \\$1.44         |\n",
        "\n",
        "**SS_res = 1.90, SS_tot = 21.80**\n",
        "\n",
        "**RÂ² = 1 - (1.90 Ã· 21.80) = 1 - 0.087 = 0.913**\n"
      ],
      "metadata": {
        "id": "oYHxWAbvMgQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using sklearn:**"
      ],
      "metadata": {
        "id": "qc7EYQXrNPMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2 = r2_score(actual_tips, predicted_tips)\n",
        "print(f\"RÂ²: {r2:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRSO5kgyNQIr",
        "outputId": "7d052d56-bfd7-4730-e139-1fc0c436c2fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RÂ²: 0.913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means our model explains about 91.3% of the variance in tip amounts!"
      ],
      "metadata": {
        "id": "0u2fT9LtNUXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding R-squared Values\n",
        "\n",
        "- **RÂ² = 1.0:** Perfect predictions (our model explains everything)\n",
        "- **RÂ² = 0.8:** Good model (explains 80% of variance)\n",
        "- **RÂ² = 0.5:** Moderate model (explains 50% of variance)  \n",
        "- **RÂ² = 0.0:** Our model is no better than just guessing the average\n",
        "- **RÂ² < 0:** Our model is worse than just guessing the average\n"
      ],
      "metadata": {
        "id": "pHU9lSSNNaHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to Use R-squared\n",
        "\n",
        "**Metric Type:** ðŸŸ¢ **Positive Metric** (Higher is Better)\n",
        "- We want RÂ² to be as close to 1.0 as possible\n",
        "- RÂ² = 1.0 means perfect predictions, RÂ² = 0 means your model is no better than guessing the average\n",
        "\n",
        "**Key Properties:**\n",
        "- **Relative performance:** Great for comparing different models\n",
        "- **Proportion of variance explained:** Tells us how much of the \"story\" our model captures\n",
        "- **Standardized:** Always between 0 and 1 (for good models)\n",
        "\n",
        "**Best for:**\n",
        "\n",
        "When we want to understand how much predictive power our model has compared to a baseline, and when comparing different models on the same dataset.\n",
        "\n",
        "- **Marketing campaign effectiveness:** Predicting sales based on advertising spend, where RÂ² shows what percentage of sales variation our model can explain to justify budget allocation.\n",
        "- **Educational assessment:** When predicting student test scores, RÂ² helps educators understand how much of the performance variation can be explained by the factors in our model."
      ],
      "metadata": {
        "id": "QYhdZOeYNseP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Mean Absolute Percentage Error (MAPE)\n",
        "\n",
        "MAPE just tries to express errors as percentages of the actual values, making it easy to understand regardless of the scale of our data. We can also think of it as: *\"On average, what percentage are we off by?\"*\n",
        "\n",
        "\n",
        "**Formula:** MAPE = (1/n) Ã— Î£|(actual - predicted) / actual| Ã— 100"
      ],
      "metadata": {
        "id": "qc6Uhjf_OYiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Calculation"
      ],
      "metadata": {
        "id": "mxeaiLR9RVxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Manual Calculation:**\n",
        "\n",
        "| Table | Actual Tip | Predicted Tip | Absolute % Error |\n",
        "|-------|------------|---------------|------------------|\n",
        "| 1     | \\$4.00      | \\$3.50         | 12.5%           |\n",
        "| 2     | \\$6.00      | \\$5.80         | 3.3%            |\n",
        "| 3     | \\$2.00      | \\$2.90         | 45.0%           |\n",
        "| 4     | \\$8.00      | \\$7.20         | 10.0%           |\n",
        "| 5     | \\$3.50      | \\$3.10         | 11.4%           |\n",
        "\n",
        "**MAPE = (12.5 + 3.3 + 45.0 + 10.0 + 11.4) Ã· 5 = 16.4%**\n"
      ],
      "metadata": {
        "id": "krO7N0MsRXOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Python (sklearn doesn't have MAPE, so we can create our own):**"
      ],
      "metadata": {
        "id": "37_qCf6_RiPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(actual, predicted):\n",
        "    return np.mean(np.abs((actual - predicted) / actual)) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(actual_tips, predicted_tips)\n",
        "print(f\"MAPE: {mape:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC7qvxZ8z2_Y",
        "outputId": "dd63e166-bc9c-44a2-cae3-541ec89a186b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE: 16.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that on average, our predictions are off by about 16.4%."
      ],
      "metadata": {
        "id": "aDYcutER0d1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAPE Interpretation Guidelines\n",
        "\n",
        "- **< 10%:** Excellent accuracy\n",
        "- **10-20%:** Good accuracy  \n",
        "- **20-50%:** Reasonable accuracy\n",
        "- **> 50%:** Poor accuracy\n"
      ],
      "metadata": {
        "id": "bc0ygdeISNJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to Use MAPE\n",
        "\n",
        "**Metric Type:** ðŸ”´ **Negative Metric** (Lower is Better)\n",
        "- We want MAPE to be as close to 0% as possible\n",
        "- MAPE = 0% means perfect predictions\n",
        "\n",
        "**Key Properties:**\n",
        "- **Scale-independent:** Useful when comparing models across different datasets\n",
        "- **Intuitive:** Everyone understands percentages\n",
        "\n",
        "\n",
        "**Best for:**\n",
        "\n",
        "When we need to communicate model performance to non-technical stakeholders, or when comparing models across different scales.\n",
        "\n",
        "- **Sales forecasting:** When predicting monthly sales revenue, MAPE = 8% tells business managers that forecasts are typically within 8% of actual sales.\n",
        "- **Inventory management:** Predicting product demand where MAPE helps retailers understand typical forecast accuracy in percentage terms, making it easy to set safety stock levels."
      ],
      "metadata": {
        "id": "1P5JtE_70l6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Choosing the Right Loss Function\n",
        "\n",
        "Now that we understand each loss function, how do we choose which one to use? We can follow the guide below:\n",
        "\n",
        "### Use MAE when:\n",
        "- We want easy interpretation\n",
        "- Outliers shouldn't dominate our evaluation\n",
        "- All errors should be treated equally\n",
        "- We're explaining results to non-technical stakeholders\n",
        "\n",
        "### Use MSE when:\n",
        "- Large errors can be costly\n",
        "- We're training a model (works great with optimization algorithms)\n",
        "\n",
        "### Use RMSE when:\n",
        "- We want MSE's properties but need interpretable units\n",
        "- We want a balance between interpretability and mathematical properties\n",
        "\n",
        "### Use R-squared when:\n",
        "- We want to compare different models\n",
        "- We need to understand what proportion of variance is explained\n",
        "\n",
        "### Use MAPE when:\n",
        "- We need scale-independent comparison\n",
        "- Percentage errors make business sense\n",
        "- We're presenting to executives or clients\n"
      ],
      "metadata": {
        "id": "Iv8_P_I81bIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Key Takeaways\n",
        "\n",
        "Understanding loss functions is crucial for building better models and communicating results effectively. Here's something to remember:\n",
        "\n",
        "1. **MAE** gives us the average error in original units, it's simple and robust\n",
        "2. **MSE** penalizes large errors heavily, it's great for optimization\n",
        "3. **RMSE** combines MSE's properties with interpretable units\n",
        "4. **R-squared** tells us the proportion of variance explained, it's perfect for model comparison\n",
        "5. **MAPE** provides percentage-based errors which makes it excellent for business communication"
      ],
      "metadata": {
        "id": "xYT0UuUM1e1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best practice would be to not rely on just one metric but rather use multiple loss functions to get a complete picture of the model's performance. Each metric tells a different part of the story, and together they provide the insights needed to build better, more reliable models.\n",
        "\n",
        "*Remember: The goal is not just to minimize error but also to build models that make reliable, useful predictions in the real world.*"
      ],
      "metadata": {
        "id": "3wNGWJ7KWC12"
      }
    }
  ]
}